{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from subprocess import check_output\n",
    "pd.set_option(\"display.max_columns\",999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'DataFiles/'\n",
    "df_seeds = pd.read_csv(data_dir + 'NCAATourneySeeds.csv')\n",
    "df_tour = pd.read_csv(data_dir + 'NCAATourneyDetailedResults.csv')\n",
    "df_reg = pd.read_csv(data_dir + 'RegularSeasonDetailedResults.csv')\n",
    "df_all = pd.concat([df_tour,df_reg],axis=0)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_pos = df_all.apply(lambda row: 0.96*(row.WFGA + row.WTO + 0.44*row.WFTA - row.WOR), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possessions\n",
    "w_pos = df_all.apply(lambda row: 0.96*(row.WFGA + row.WTO + 0.44*row.WFTA - row.WOR), axis=1)\n",
    "l_pos = df_all.apply(lambda row: 0.96*(row.LFGA + row.LTO + 0.44*row.LFTA - row.LOR), axis=1)\n",
    "df_all['Pos'] = (w_pos+l_pos)/2\n",
    "\n",
    "#Offensive efficiency (OffRtg) = 100 x (Points / Possessions)\n",
    "df_all['WOffRtg'] = df_all.apply(lambda row: 100 * (row.WScore / row.Pos), axis=1)\n",
    "df_all['LOffRtg'] = df_all.apply(lambda row: 100 * (row.LScore / row.Pos), axis=1)\n",
    "#Defensive efficiency (DefRtg) = 100 x (Opponent points / Opponent possessions)\n",
    "df_all['WDefRtg'] = df_all.LOffRtg\n",
    "df_all['LDefRtg'] = df_all.WOffRtg\n",
    "#Net Rating = Off.Rtg - Def.Rtg\n",
    "df_all['WNetRtg'] = df_all.apply(lambda row:(row.WOffRtg - row.WDefRtg), axis=1)\n",
    "df_all['LNetRtg'] = df_all.apply(lambda row:(row.LOffRtg - row.LDefRtg), axis=1)\n",
    "                         \n",
    "#Assist Ratio : Percentage of team possessions that end in assists\n",
    "df_all['WAstR'] = df_all.apply(lambda row: 100 * row.WAst / (row.WFGA + 0.44*row.WFTA + row.WAst + row.WTO), axis=1)\n",
    "df_all['LAstR'] = df_all.apply(lambda row: 100 * row.LAst / (row.LFGA + 0.44*row.LFTA + row.LAst + row.LTO), axis=1)\n",
    "#Turnover Ratio: Number of turnovers of a team per 100 possessions used.\n",
    "#(TO * 100) / (FGA + (FTA * 0.44) + AST + TO)\n",
    "df_all['WTOR'] = df_all.apply(lambda row: 100 * row.WTO / (row.WFGA + 0.44*row.WFTA + row.WAst + row.WTO), axis=1)\n",
    "df_all['LTOR'] = df_all.apply(lambda row: 100 * row.LTO / (row.LFGA + 0.44*row.LFTA + row.LAst + row.LTO), axis=1)\n",
    "                    \n",
    "#The Shooting Percentage : Measure of Shooting Efficiency (FGA/FGA3, FTA)\n",
    "df_all['WTSP'] = df_all.apply(lambda row: 100 * row.WPts / (2 * (row.WFGA + 0.44 * row.WFTA)), axis=1)\n",
    "df_all['LTSP'] = df_all.apply(lambda row: 100 * row.LPts / (2 * (row.LFGA + 0.44 * row.LFTA)), axis=1)\n",
    "#eFG% : Effective Field Goal Percentage adjusting for the fact that 3pt shots are more valuable \n",
    "df_all['WeFGP'] = df_all.apply(lambda row:(row.WFGM + 0.5 * row.WFGM3) / row.WFGA, axis=1)      \n",
    "df_all['LeFGP'] = df_all.apply(lambda row:(row.LFGM + 0.5 * row.LFGM3) / row.LFGA, axis=1)   \n",
    "#FTA Rate : How good a team is at drawing fouls.\n",
    "df_all['WFTAR'] = df_all.apply(lambda row: row.WFTA / row.WFGA, axis=1)\n",
    "df_all['LFTAR'] = df_all.apply(lambda row: row.LFTA / row.LFGA, axis=1)\n",
    "                         \n",
    "#OREB% : Percentage of team offensive rebounds\n",
    "df_all['WORP'] = df_all.apply(lambda row: row.WOR / (row.WOR + row.LDR), axis=1)\n",
    "df_all['LORP'] = df_all.apply(lambda row: row.LOR / (row.LOR + row.WDR), axis=1)\n",
    "#DREB% : Percentage of team defensive rebounds\n",
    "df_all['WDRP'] = df_all.apply(lambda row: row.WDR / (row.WDR + row.LOR), axis=1)\n",
    "df_all['LDRP'] = df_all.apply(lambda row: row.LDR / (row.LDR + row.WOR), axis=1)                                      \n",
    "#REB% : Percentage of team total rebounds\n",
    "df_all['WRP'] = df_all.apply(lambda row: (row.WDR + row.WOR) / (row.WDR + row.WOR + row.LDR + row.LOR), axis=1)\n",
    "df_all['LRP'] = df_all.apply(lambda row: (row.LDR + row.WOR) / (row.WDR + row.WOR + row.LDR + row.LOR), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_keeps =  [col for col in df_tour.columns if 'W' in col]\n",
    "l_keeps =  [col for col in df_tour.columns if 'L' in col]\n",
    "new_names = [name[1:] for name in w_keeps]\n",
    "#new_names == [name[1:] for name in l_keeps] #check that sets are identical\n",
    "w_tour = df_tour.copy()\n",
    "w_tour = w_tour[w_keeps]\n",
    "w_tour.columns = new_names\n",
    "l_tour = df_tour.copy()\n",
    "l_tour = l_tour[l_keeps]\n",
    "l_tour.columns = new_names\n",
    "stack_tour = pd.concat([w_tour,l_tour])\n",
    "team_means = stack_tour.groupby(['TeamID'], as_index=False).mean()\n",
    "team_stds = stack_tour.groupby(['TeamID'], as_index=False).std()\n",
    "team_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_to_int(seed):\n",
    "    s_int = int(seed[1:3])\n",
    "    return s_int\n",
    "df_seeds['seed_int'] = df_seeds.Seed.apply(seed_to_int)\n",
    "df_seeds.drop(labels=['Seed'], inplace=True, axis=1) # This is the string label\n",
    "df_seeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min = df_tour[['Season','WTeamID','LTeamID']]\n",
    "df_min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins = df_seeds.copy()\n",
    "df_wins = pd.merge(left=df_wins,right=team_means,how='left',on=['TeamID'])\n",
    "df_wins = pd.merge(left=df_wins,right=team_stds,how='left',on=['TeamID'])\n",
    "df_wins.drop(labels=['Score'],inplace=True,axis=1) #there are teams where we have Non team_mean\n",
    "df_w_names = ['W'+i for i in df_wins.columns]\n",
    "df_wins.columns = df_w_names\n",
    "df_losses = df_seeds.copy()\n",
    "df_losses = pd.merge(left=df_losses,right=team_means,how='left',on=['TeamID'])\n",
    "df_losses = pd.merge(left=df_losses,right=team_stds,how='left',on=['TeamID'])\n",
    "df_losses.drop(labels=['Score'],inplace=True,axis=1)\n",
    "df_l_names = ['L'+i for i in df_losses.columns]\n",
    "df_losses.columns = df_l_names\n",
    "df_dummy = pd.merge(left=df_min, right=df_wins, how='left', left_on=['Season', 'WTeamID'],right_on=['WSeason','WTeamID'])\n",
    "df_concat = pd.merge(left=df_dummy, right=df_losses, left_on=['Season', 'LTeamID'],right_on=['LSeason','LTeamID'])\n",
    "df_concat['SeedDiff'] = df_concat.Wseed_int - df_concat.Lseed_int\n",
    "for i in new_names[3:]:\n",
    "    df_concat[i+'Diff'] = df_concat['W'+i]-df_concat['L'+i]\n",
    "    df_concat.drop(labels=['W'+i,'L'+i],inplace=True,axis=1)\n",
    "df_concat.drop(labels=['Season','WSeason','LSeason','Wseed_int','Lseed_int'],inplace=True,axis=1)\n",
    "df_concat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_win_pred = df_concat.copy()\n",
    "df_win_pred.drop(labels=['LTeamID'],inplace=True,axis=1)\n",
    "df_win_pred = df_win_pred.rename(columns={'WTeamID':'TeamID'})\n",
    "df_win_pred['result'] = 1\n",
    "\n",
    "df_loss_pred = df_concat.copy()\n",
    "df_loss_pred.drop(labels=['WTeamID'],inplace=True,axis=1)\n",
    "df_loss_pred = df_loss_pred.rename(columns={'LTeamID':'TeamID'})\n",
    "df_loss_pred.iloc[:,1:] = -df_loss_pred.iloc[:,1:]\n",
    "df_loss_pred['result'] = 0\n",
    "\n",
    "df_predictions = pd.concat((df_win_pred, df_loss_pred))\n",
    "df_predictions.drop(labels=['TeamID'], inplace=True, axis=1)\n",
    "df_loss_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_predictions.copy()\n",
    "X_train.drop(labels=['result'],inplace=True,axis=1)\n",
    "y_train = df_predictions.result.values\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "params = {'C': np.logspace(start=-5, stop=3, num=9)}\n",
    "clf = GridSearchCV(logreg, params, scoring='neg_log_loss', refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Best log_loss: {:.4}, with best C: {}'.format(clf.best_score_, clf.best_params_['C']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_sub = pd.read_csv(data_dir + 'SampleSubmissionStage1.csv')\n",
    "n_test_games = len(df_sample_sub)\n",
    "\n",
    "def get_year_t1_t2(ID):\n",
    "    \"\"\"Return a tuple with ints `year`, `team1` and `team2`.\"\"\"\n",
    "    return (int(x) for x in ID.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_sub.head()\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros(shape=(n_test_games, X_train.shape[1]))\n",
    "for ii, row in df_sample_sub.iterrows():\n",
    "    year, t1, t2 = get_year_t1_t2(row.ID)\n",
    "    t1_seed = df_seeds[(df_seeds.TeamID == t1) & (df_seeds.Season == year)].seed_int.values[0]\n",
    "    t2_seed = df_seeds[(df_seeds.TeamID == t2) & (df_seeds.Season == year)].seed_int.values[0]\n",
    "    diff_seed = t1_seed - t2_seed\n",
    "    X_test[ii, 0] = diff_seed\n",
    "    i = 1\n",
    "    for name in new_names[3:]:\n",
    "        val1 = float(team_means.loc[(team_means.TeamID == t1),name])\n",
    "        val2 = float(team_means.loc[(team_means.TeamID == t2),name])\n",
    "        X_test[ii,i] = val1-val2\n",
    "        i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "clipped_preds = np.clip(preds, 0.05, 0.95)\n",
    "df_sample_sub.Pred = clipped_preds\n",
    "df_sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_sub.to_csv('logreg_extra_vars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense,Activation,Conv1D,MaxPooling1D,GlobalAveragePooling1D,Dropout\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = pd.DataFrame()\n",
    "y_class['win'] = y_train\n",
    "y_class['lose'] = 1-y_train\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, activation='relu', input_shape = (X_train.shape[1],)))\n",
    "    model.add(Dense(50, activation='relu', input_shape = (X_train.shape[1],)))\n",
    "    model.add(Dense(30, activation='relu', input_shape = (X_train.shape[1],)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy')\n",
    "    return(model)\n",
    "\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "models = []\n",
    "scores = []\n",
    "for i, (train, test) in enumerate(skf.split(X_train,y_class.win)):\n",
    "        print('Running Fold', i+1, \"/\", n_folds)\n",
    "        model = None\n",
    "        model = create_model()\n",
    "        model.fit(X_train.iloc[train,],y_class.iloc[train,],\n",
    "                  epochs=20,\n",
    "                  validation_data=(X_train.iloc[test,],y_class.iloc[test,]), \n",
    "                  callbacks=[early_stopping_monitor],\n",
    "                  verbose=0)\n",
    "        predictions_valid = model.predict(X_train.iloc[test,].astype('float32'))#, verbose=2)\n",
    "        predictions_valid = np.clip(predictions_valid, 0.05, 0.95)\n",
    "        score = log_loss(y_class.iloc[test,], predictions_valid)\n",
    "        scores.append(score)\n",
    "        print('Log loss: ', score)\n",
    "        models.append(model)\n",
    "print('Average log loss: ',np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i,model in enumerate(models):\n",
    "    pred_list.append(models[i].predict(X_test)[:,0])\n",
    "pred = np.mean(pred_list,0)\n",
    "clipped_pred = np.clip(pred, 0.05, 0.95)\n",
    "df_sample_sub.Pred = clipped_pred\n",
    "df_sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_sub.to_csv('nn_extra_vars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = pd.DataFrame()\n",
    "y_class['win'] = y_train\n",
    "y_class['lose'] = 1-y_train\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "X_train_conv = np.expand_dims(X_train, axis=2)\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(20,2,padding='same',input_shape=(X_train.shape[1],1))) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(20,2,padding='same')) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy')\n",
    "    return(model)\n",
    "\n",
    "\n",
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "models = []\n",
    "scores = []\n",
    "for i, (train, test) in enumerate(skf.split(X_train,y_class.win)):\n",
    "        print('Running Fold', i+1, \"/\", n_folds)\n",
    "        model = None\n",
    "        model = create_model()\n",
    "        model.fit(X_train_conv[train],y_class.iloc[train,],\n",
    "                  epochs=20,\n",
    "                  validation_data=(X_train_conv[test],y_class.iloc[test,]), \n",
    "                  callbacks=[early_stopping_monitor],\n",
    "                  verbose=0)\n",
    "        predictions_valid = model.predict(X_train_conv[test].astype('float32'))#, verbose=2)\n",
    "        predictions_valid = np.clip(predictions_valid, 0.05, 0.95)\n",
    "        score = log_loss(y_class.iloc[test,], predictions_valid)\n",
    "        scores.append(score)\n",
    "        print('Log loss: ', score)\n",
    "        models.append(model)\n",
    "print('Average log loss: ',np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
